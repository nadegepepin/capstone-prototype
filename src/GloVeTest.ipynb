{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GloVepreprocessing\n",
    "import model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Lambda \n",
    "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, AveragePooling2D, Reshape, LSTM, Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = GloVepreprocessing.GloVepreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preprocessor.tokenizer.get_config().keys())\n",
    "print(len(preprocessor.tokenizer.get_config()['word_counts']))\n",
    "print(len(preprocessor.tokenizer.get_config()['word_index']))\n",
    "print(len(preprocessor.tokenizer.get_config()['index_word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={\"la\":0, \"le\":1, \"li\":2}\n",
    "dict2={\"lustucru\":0, \"lu\":1, \"lou\":2, \"bli\":3}\n",
    "dict2.pop(\"lustucru\")\n",
    "n = len(dict1)\n",
    "newdict = dict1\n",
    "for key, value in dict2.items():\n",
    "    newdict[key]=int(value)+n-1\n",
    "print(newdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Il etait une fois\", \"Y'en a marre de cette chanson la!\"]\n",
    "\n",
    "embedded_list = preprocessor.GloVe_embed(sentences, preprocessor.weights, isInputSentence=False)\n",
    "print(embedded_list)\n",
    "print(np.reshape(embedded_list, (2,35,50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "CLS_IDX = 1\n",
    "SEP_IDX = 2\n",
    "UNKNOWN_IDX = 3\n",
    "preword2idx = { '[PAD]': PAD_IDX, '[CLS]': CLS_IDX, '[SEP]': SEP_IDX, '[UNK]': UNKNOWN_IDX}\n",
    "preidx2word = { PAD_IDX :'[PAD]' , CLS_IDX :'[CLS]' , SEP_IDX :'[SEP]' , UNKNOWN_IDX :'[UNK]'}        \n",
    "\n",
    "postword2idx = preprocessor.tokenizer.word_index\n",
    "postidx2word = preprocessor.tokenizer.index_word\n",
    "\n",
    "n = len(preword2idx)\n",
    "\n",
    "word2idx = preword2idx\n",
    "idx2word = preidx2word\n",
    "for key, value in postword2idx.items():\n",
    "    word2idx[key]=int(value)+n-1\n",
    "for key, value in postidx2word.items():\n",
    "    idx2word[int(key)+n-1]=value\n",
    "print(idx2word)\n",
    "#print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_batch = preprocessor.batch_generator(\"train\",0, 20)\n",
    "print(len(my_batch[1][\"caption_output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessor = GloVepreprocessing.GloVepreprocessor()\n",
    "\n",
    "X, Y  = preprocessor.batch_generator(\"train\", 0, 100)\n",
    "\n",
    "\n",
    "mymodel = model.TrainShowAndTell(preprocessor.MAX_SEQUENCE_LENGTH, preprocessor.VOCAB_SIZE, preprocessor.EMBEDDING_SIZE, 60, preprocessor.weights)\n",
    "\n",
    "mymodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr = 0.01), metrics=['accuracy'])\n",
    "\n",
    "a0 = np.zeros((X[\"image_input\"].shape[0], 60))\n",
    "c0 = np.zeros((X[\"image_input\"].shape[0], 60))\n",
    "\n",
    "mymodel.fit([X[\"image_input\"],X[\"caption_input\"]\n",
    "             , a0, c0], Y[\"caption_output\"], batch_size=10, epochs=9, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(captions, max_caption_length, n_classes):\n",
    "    hot_encoding = np.zeros((len(captions), max_caption_length, n_classes))\n",
    "    for i, caption in enumerate(captions):\n",
    "        for j, idx in enumerate(caption):\n",
    "            hot_encoding[i, j, idx] = 1.0\n",
    "        for k in range(j+1, max_caption_length):\n",
    "            hot_encoding[i, k, preprocessor.word2idx[\"[PAD]\"]] = 1.0\n",
    "\n",
    "    return hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[array([[ 973, 1977,    5,  114,    2,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0]], dtype=int32), array([[   7,    5, 1167,  439, 1753,    2,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0]], dtype=int32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 1., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 1., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = [\"once upon a time\",\"in a far away cabin\"]\n",
    "list_of_captions_ids = preprocessor.get_sentences_ids(preprocessor.preprocess_sentences(captions), preprocessor.tokenizer, isInputSentence=False)\n",
    "print(len(list_of_captions_ids))\n",
    "print(list(list_of_captions_ids))\n",
    "one_hot_encode(list_of_captions_ids,35,preprocessor.VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  list_of_captions_ids = self.get_sentences_ids(self.preprocess_sentences(list_of_captions), self.tokenizer, isInputSentence)\n",
    "    \n",
    "        for caption_ids in list_of_captions_ids:\n",
    "            for id in caption_ids:\n",
    "                caption_embedding = []\n",
    "                caption_embedding.append(self.weights[id])\n",
    "            embeddings.extend(caption_embedding)\n",
    "    \n",
    "        return embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(model, tokenizer, image, max_length):\n",
    "\t# Seed the generation process\n",
    "\tin_text = 'startseq'\n",
    "\t# Iterate over the whole length of the sequence\n",
    "\tfor _ in range(max_length):\n",
    "\t\t# Integer encode input sequence\n",
    "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# Pad input\n",
    "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
    "\t\t# Predict next word\n",
    "\t\t# The model will output a prediction, which will be a probability distribution over all words in the vocabulary.\n",
    "\t\tyhat = model.predict([image,sequence], verbose=0)\n",
    "\t\t# The output vector representins a probability distribution where maximum probability is the predicted word position\n",
    "\t\t# Take output class with maximum probability and convert to integer\n",
    "\t\tyhat = np.argmax(yhat)\n",
    "\t\t# Map integer back to word\n",
    "\t\tword = int_to_word(yhat, tokenizer)\n",
    "\t\t# Stop if we cannot map the word\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\t# Append as input for generating the next word\n",
    "\t\tin_text += ' ' + word\n",
    "\t\t# Stop if we predict the end of the sequence\n",
    "\t\tif word == 'endseq':\n",
    "\t\t\tbreak\n",
    "\treturn in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
