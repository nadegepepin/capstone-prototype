{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to test the data loading modules (storage.py, extraction.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import logging\n",
    "import logging.config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import string\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "sys.path.append('/src/capstone-prototype/src/')\n",
    "from config import settings\n",
    "import storage\n",
    "import extraction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"../\"+settings.log_config\n",
    "def setupLogging():\n",
    "    with open(log_file_path, 'rt') as file:\n",
    "        config = yaml.safe_load(file.read())\n",
    "        logging.config.dictConfig(config)\n",
    "setupLogging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setupLogging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV files\n",
    "train_rawdata_file_path = settings.train_raw_data\n",
    "validation_rawdata_file_path = settings.validation_raw_data\n",
    "\n",
    "#train_df = pd.read_table(train_rawdata_file_path, header = None, names = ['caption', 'url'] )\n",
    "validate_df = pd.read_table(validation_rawdata_file_path, header = None, names = ['caption', 'url']) \n",
    "\n",
    "#train_df.head(20)\n",
    "validate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['caption'].str.contains(\"panda\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts image and caption from tsv and store padded(image),caption and HTTPStatus code\n",
    "# into a train or validation hdf5 file\n",
    "\n",
    "# Set image size\n",
    "img_size = 300 , 300 \n",
    "start_index = 0\n",
    "\n",
    "# Extraction and Storage\n",
    "#extraction.request_data_and_store(validate_df, size, \"validate\", start_index) \n",
    "#extraction.request_data_and_store(train_df, size, \"train\", start_index - 100)\n",
    "extraction.request_data_and_store(validate_df, img_size, \"train_le_retour\", start_index)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(set_name, img_size, start_index=0, extraction_size=100000):\n",
    "# Extracts image and caption from tsv and store padded(image),caption and HTTPStatus code\n",
    "# into a train or validation hdf5 file\n",
    "    logger = logging.getLogger()\n",
    "    data_df = None\n",
    "    if set_name == \"train\":\n",
    "        # Read TSV file\n",
    "        train_rawdata_file_path = \"../\"+settings.train_raw_data\n",
    "        data_df = pd.read_table(train_rawdata_file_path, header = None, names = ['caption', 'url'] )\n",
    "        \n",
    "    elif set_name == \"validate\":\n",
    "        # Read TSV file\n",
    "        validation_rawdata_file_path = \"../\"+settings.validation_raw_data\n",
    "        data_df = pd.read_table(validation_rawdata_file_path, header = None, names = ['caption', 'url']) \n",
    "\n",
    "    else:\n",
    "        logger.info(\"loader.extract_data: get yout set_name right! What is it you want to load again?\")\n",
    "        return\n",
    "    \n",
    "    # Extract images and stores images/captions\n",
    "    #data_df = data_df.head(40)\n",
    "    extraction.request_data_and_store(data_df, img_size, set_name, start_index, extraction_size)\n",
    "    logger.info(\"loader.extract_data: all the data have been extracted and stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 16:51:05,820 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before ACQUIRE -- 1200010\n",
      "2020-10-03 16:51:05,825 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before SUBMIT -- 1200010\n",
      "2020-10-03 16:51:05,831 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_0 - root - INFO - train-- Fetching URL#1200010\n",
      "2020-10-03 16:51:05,855 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before ACQUIRE -- 1200011\n",
      "2020-10-03 16:51:05,859 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before SUBMIT -- 1200011\n",
      "2020-10-03 16:51:05,862 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_1 - root - INFO - train-- Fetching URL#1200011\n",
      "2020-10-03 16:51:05,877 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before ACQUIRE -- 1200012\n",
      "2020-10-03 16:51:05,882 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before SUBMIT -- 1200012\n",
      "2020-10-03 16:51:05,885 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_2 - root - INFO - train-- Fetching URL#1200012\n",
      "2020-10-03 16:51:05,901 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before ACQUIRE -- 1200013\n",
      "2020-10-03 16:51:05,906 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before SUBMIT -- 1200013\n",
      "2020-10-03 16:51:05,913 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_3 - root - INFO - train-- Fetching URL#1200013\n",
      "2020-10-03 16:51:05,929 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before ACQUIRE -- 1200014\n",
      "2020-10-03 16:51:05,936 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - extraction:request_data_and_store-- Before SUBMIT -- 1200014\n",
      "2020-10-03 16:51:05,940 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_4 - root - INFO - train-- Fetching URL#1200014\n",
      "2020-10-03 16:51:06,128 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_1 - root - INFO - train-- URL#1200011 Http code: 200\n",
      "2020-10-03 16:51:06,137 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_0 - root - INFO - train-- URL#1200010 Http code: 200\n",
      "2020-10-03 16:51:06,148 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_1 - root - INFO - https://pictures.escapia.com/ALIIBR/7142970327.jpg\n",
      "2020-10-03 16:51:06,149 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_3 - root - INFO - train-- URL#1200013 Http code: 200\n",
      "2020-10-03 16:51:06,154 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_0 - root - INFO - https://ak9.picdn.net/shutterstock/videos/12139049/thumb/7.jpg?i10c=img.resize(height:160)\n",
      "2020-10-03 16:51:06,163 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_3 - root - INFO - http://i.dailymail.co.uk/i/pix/2013/03/01/article-2286487-185F9094000005DC-20_634x451.jpg\n",
      "2020-10-03 16:51:06,172 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_1 - root - INFO - train-- Store Handler Index#1200011 Http code: 200\n",
      "2020-10-03 16:51:06,180 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_0 - root - INFO - train-- Store Handler Index#1200010 Http code: 200\n",
      "2020-10-03 16:51:06,186 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_1 - root - INFO - storage.store_imagetrain-- INDEX#1200011 STORING--- \n",
      "2020-10-03 16:51:06,188 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_0 - root - INFO - storage.store_imagetrain-- INDEX#1200010 STORING--- \n",
      "2020-10-03 16:51:06,191 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_3 - root - INFO - train-- Store Handler Index#1200013 Http code: 200\n",
      "2020-10-03 16:51:06,204 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_1 - root - INFO - storage.store_imagetrain-- URL#1200011 IMAGE STORED--- \n",
      "2020-10-03 16:51:06,206 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_3 - root - INFO - storage.store_imagetrain-- INDEX#1200013 STORING--- \n",
      "2020-10-03 16:51:06,234 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_3 - root - INFO - storage.store_imagetrain-- URL#1200013 IMAGE STORED--- \n",
      "2020-10-03 16:51:06,272 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_0 - root - INFO - storage.store_imagetrain-- URL#1200010 IMAGE STORED--- \n",
      "2020-10-03 16:51:06,688 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_4 - root - INFO - train-- URL#1200014 Http code: 200\n",
      "2020-10-03 16:51:06,691 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_4 - root - INFO - http://media.gettyimages.com/photos/model-walks-the-runway-at-the-dolce-gabbana-spring-summer-2016-show-picture-id490289284\n",
      "2020-10-03 16:51:06,706 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_4 - root - INFO - train-- Store Handler Index#1200014 Http code: 200\n",
      "2020-10-03 16:51:06,710 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_4 - root - INFO - storage.store_imagetrain-- INDEX#1200014 STORING--- \n",
      "2020-10-03 16:51:06,726 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_4 - root - INFO - storage.store_imagetrain-- URL#1200014 IMAGE STORED--- \n",
      "2020-10-03 16:51:06,737 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_2 - root - INFO - train-- URL#1200012 Http code: 200\n",
      "2020-10-03 16:51:06,740 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_2 - root - INFO - http://l7.alamy.com/zooms/3e852730fdfc4e1c940aaeed6a7776f4/four-year-old-mexican-american-boy-eats-potato-chips-for-a-snack-on-bwh8th.jpg\n",
      "2020-10-03 16:51:06,754 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_2 - root - INFO - train-- Store Handler Index#1200012 Http code: 200\n",
      "2020-10-03 16:51:06,757 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_2 - root - INFO - storage.store_imagetrain-- INDEX#1200012 STORING--- \n",
      "2020-10-03 16:51:06,779 - INFO <PID 46046:MainProcess> - ThreadPoolExecutor-3_2 - root - INFO - storage.store_imagetrain-- URL#1200012 IMAGE STORED--- \n",
      "2020-10-03 16:51:06,788 - INFO <PID 46046:MainProcess> - MainThread - root - INFO - loader.extract_data: all the data have been extracted and stored.\n"
     ]
    }
   ],
   "source": [
    "# Get last stored index\n",
    "#last_index = storage.get_last_stored_index(\"train\")\n",
    "#print(last_index)\n",
    "\n",
    "size = 224, 224\n",
    "extract_data(\"train\", size, 1200005,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import settings\n",
    "print(settings.data_path)\n",
    "print(settings.start_seq)\n",
    "print(settings.end_seq)\n",
    "print(settings.image_shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data_and_store(\"xxtrain\", 10, 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " extraction.extract_resnet_features_and_store(\"train\", 10184, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_caption(caption):\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    # tokenize\n",
    "    desc = caption.split()\n",
    "    # convert to lower case\n",
    "    desc = [word.lower() for word in desc]\n",
    "    # remove punctuation from each token\n",
    "    desc = [w.translate(table) for w in desc]\n",
    "    # remove hanging 's' and 'a'\n",
    "    desc = [word for word in desc if len(word)>1]\n",
    "    # remove tokens with numbers in them\n",
    "    desc = [word for word in desc if word.isalpha()]\n",
    "    # store as string\n",
    "    caption = settings.start_seq +\" \"+ ' '.join(desc) +\" \"+ settings.end_seq\n",
    "    return caption\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_caption(\"Les 3 petits cochons $ et *?\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_caption(caption):\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    # tokenize\n",
    "    desc = caption.split()\n",
    "    # convert to lower case\n",
    "    desc = [word.lower() for word in desc]\n",
    "    # remove punctuation from each token\n",
    "    desc = [w.translate(table) for w in desc]\n",
    "    # remove hanging 's' and 'a'\n",
    "    desc = [word for word in desc if len(word)>1]\n",
    "    # remove tokens with numbers in them\n",
    "    desc = [word for word in desc if word.isalpha()]\n",
    "    # store as string\n",
    "    #caption = settings.start_seq +\" \"+ ' '.join(desc) +\" \"+ settings.end_seq\n",
    "    return ' '.join(desc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_caption(caption):\n",
    "    desc = settings.start_seq +\" \"+ clean_caption(caption) +\" \"+ settings.end_seq\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_caption(\"Les 3 petits cochons $ et *?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
