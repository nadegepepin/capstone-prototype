{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import logging.config\n",
    "import yaml\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import  array_to_img, img_to_array\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "\n",
    "import storage\n",
    "import extraction\n",
    "import captiongeneration\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import urllib\n",
    "import re\n",
    "from itertools import chain\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Lambda, GlobalAveragePooling2D , AveragePooling2D \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "import logging.config\n",
    "def setupLogging():\n",
    "    with open('../config/logConfig.yml', 'rt') as file:\n",
    "        config = yaml.safe_load(file.read())\n",
    "        logging.config.dictConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setupLogging()\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14 21:24:27,288 - INFO <PID 714:MainProcess> - MainThread - root - INFO - loading preprocessor\n",
      "2020-05-14 21:24:27,332 - INFO <PID 714:MainProcess> - MainThread - root - INFO - reading data for caption generation\n",
      "2020-05-14 21:24:31,424 - INFO <PID 714:MainProcess> - MainThread - root - INFO - loading training  model\n",
      "2020-05-14 21:24:33,082 - INFO <PID 714:MainProcess> - MainThread - root - INFO - loading inference init model\n",
      "2020-05-14 21:24:33,085 - INFO <PID 714:MainProcess> - MainThread - root - INFO - loading inference model\n",
      "2020-05-14 21:24:33,087 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - -------------Generated Caption---------------: [CLS]\n",
      "OUTPUT SHAPE(1, 15, 10000)\n",
      "OUTPUT[SEP]\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "OUTPUTa\n",
      "2020-05-14 21:24:36,061 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word Index5\n",
      "2020-05-14 21:24:36,062 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Worda\n",
      "Generated Word Index5\n",
      "Generated Worda\n",
      "2020-05-14 21:24:36,063 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - -------------Generated Caption---------------: [CLS] a\n",
      "OUTPUT SHAPE(1, 15, 10000)\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[UNK]\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "OUTPUTof\n",
      "2020-05-14 21:24:36,493 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word Index3\n",
      "2020-05-14 21:24:36,494 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word[UNK]\n",
      "Generated Word Index3\n",
      "Generated Word[UNK]\n",
      "2020-05-14 21:24:36,498 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - -------------Generated Caption---------------: [CLS] a [UNK]\n",
      "OUTPUT SHAPE(1, 15, 10000)\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "OUTPUTin\n",
      "2020-05-14 21:24:36,932 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word Index7\n",
      "2020-05-14 21:24:36,933 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Wordin\n",
      "Generated Word Index7\n",
      "Generated Wordin\n",
      "2020-05-14 21:24:36,934 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - -------------Generated Caption---------------: [CLS] a [UNK] in\n",
      "OUTPUT SHAPE(1, 15, 10000)\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "OUTPUTthe\n",
      "2020-05-14 21:24:37,369 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word Index4\n",
      "2020-05-14 21:24:37,370 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Wordthe\n",
      "Generated Word Index4\n",
      "Generated Wordthe\n",
      "2020-05-14 21:24:37,371 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - -------------Generated Caption---------------: [CLS] a [UNK] in the\n",
      "OUTPUT SHAPE(1, 15, 10000)\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "OUTPUT[SEP]\n",
      "2020-05-14 21:24:37,935 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word Index2\n",
      "2020-05-14 21:24:37,936 - DEBUG <PID 714:MainProcess> - MainThread - root - DEBUG - Generated Word[SEP]\n",
      "Generated Word Index2\n",
      "Generated Word[SEP]\n",
      "2020-05-14 21:24:37,943 - INFO <PID 714:MainProcess> - MainThread - root - INFO - Candidate Caption: = a [UNK] in the [SEP]\n",
      "generated\n",
      "a [UNK] in the [SEP]\n",
      "old\n",
      "a silhouette of a young girl wearing a large summer hat , standing with arm extended and hand pointing towards something .\n"
     ]
    }
   ],
   "source": [
    "import captiongeneration\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "generated_caption, caption, image = captiongeneration.caption_generation(\"train\", 1530, 236)\n",
    "\n",
    "\n",
    "print(\"generated\")\n",
    "print(generated_caption)\n",
    "print(\"old\")\n",
    "print(caption)\n",
    "\n",
    "#plt.imshow(tensorflow.reshape(image, (300, 300, 3)))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, image, caption = storage.read_image(\"train\", 10002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = K.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "try:\n",
    "    with open(\"../data/preprocessor.pickle\", 'rb') as handle:\n",
    "        preprocessor = pickle.load(handle)\n",
    "except FileNotFoundError:      \n",
    "    preprocessor = GloVepreprocessing.GloVepreprocessor()\n",
    "    with open(\"../data/preprocessor.pickle\", 'wb') as handle:\n",
    "        print(\"before pickle dump\")\n",
    "        pickle.dump(preprocessor, handle)\n",
    "\n",
    "\n",
    "# Loads model and weights\n",
    "training_model, inference_initialiser_model, inference_model = model.ShowAndTell(preprocessor.MAX_SEQUENCE_LENGTH, preprocessor.VOCAB_SIZE, preprocessor.EMBEDDING_SIZE, 60, preprocessor.weights)\n",
    "\n",
    "embedded_generated_caption = preprocessor.GloVe_embed(preprocessor.get_sequences_ids([['once','upon']]))\n",
    "logger.debug(\"-------------Generated Caption---------------: \" + \" \".join(['once','upon']))\n",
    "#logger.debug(\"-------------Embedded Generated Caption---------------: \" + \" \".join(len(embedded_generated_caption)))\n",
    "len(embedded_generated_caption)\n",
    "\n",
    "#loss_function = preprocessor.get_loss_function()\n",
    "#training_model.compile(loss=loss_function, optimizer=Adam(lr = 0.001), metrics=['accuracy'])\n",
    "#training_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_word_sequence(\"once upon a time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads captions and images stored in the validate/train hdf5 files from start_index to end_index\n",
    "def read_file(set_name, start_index, end_index): \n",
    "      \n",
    "    file_nb = storage.get_file_numbers(start_index, end_index)\n",
    "\n",
    "    for nb in range(file_nb[0], file_nb[1]+1):\n",
    "        file_path, lock_path = storage.get_path(set_name, nb)\n",
    "        start_idx = nb * storage.get_file_size() if nb > file_nb[0] else start_index\n",
    "        end_idx = (nb + 1) * storage.get_file_size() if nb < file_nb[1] else end_index\n",
    "\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            try:\n",
    "                status, image, caption = storage.read_image(set_name, idx)  \n",
    "                if (int(status) == 200):\n",
    "\n",
    "                    print(image.shape)\n",
    "                    print(caption)\n",
    "                    print(image.dtype)\n",
    "\n",
    "                    x = image.reshape((1,) + image.shape)\n",
    "                    print(x.shape)\n",
    "                    plt.imshow(image)\n",
    "                    plt.show()\n",
    "\n",
    "            except KeyError:\n",
    "                # Ignores files not found - probably an HHTP error when requesting the URL\n",
    "                # Later - Keep count of the minning files to know the exact size of the dataset\n",
    "                print(\"Missing index - image not found - probably an HHTP error when requesting the URL \" + str(idx))\n",
    "                continue \n",
    "   \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file(\"train\", 1, 3)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads status stored in the validate/train hdf5 files from start_index to end_index\n",
    "def read_status(set_name, start_index, end_index): \n",
    "      \n",
    "    file_nb = storage.get_file_numbers(start_index, end_index)\n",
    "    statuslist = []\n",
    "\n",
    "    for nb in range(file_nb[0], file_nb[1]+1):\n",
    "        file_path, lock_path = storage.get_path(set_name, nb)\n",
    "        start_idx = nb * storage.get_file_size() if nb > file_nb[0] else start_index\n",
    "        end_idx = (nb + 1) * storage.get_file_size() if nb < file_nb[1] else end_index\n",
    "\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            try:\n",
    "                status, image, caption = storage.read_image(set_name, idx)  \n",
    "                statuslist.append(int(status))\n",
    "\n",
    "            except KeyError:\n",
    "                # Ignores files not found - probably an HHTP error when requesting the URL\n",
    "                # Later - Keep count of the minning files to know the exact size of the dataset\n",
    "                print(\"Missing index - image not found - probably an HHTP error when requesting the URL \" + str(idx))\n",
    "                continue \n",
    "   \n",
    "    return statuslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = pd.DataFrame(read_status(\"train\", 99910, 100099))\n",
    "print(df['status'].value_counts())\n",
    "\n",
    "plt.hist(df[\"status\"], bins = 18)\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[ 9.4755635e-02,  3.1283161e-01, -6.7922041e-02,  6.4237791e-01,\n",
    "        2.2102470e+00, -5.1988786e-01, -9.8959517e-01,  3.5088462e-01,\n",
    "        3.0951893e+00, -3.8163280e-01, -1.6836199e+00, -5.8072060e-01,\n",
    "        1.4972074e+00,  3.3191606e-01,  1.0996586e+00,  4.2056244e-02,\n",
    "        4.6159565e-01,  2.0012915e+00, -2.6618072e-01, -8.4128553e-01,\n",
    "        1.2607530e-01,  1.5344251e+00, -1.5301496e-01, -4.7858629e-01,\n",
    "       -2.9338709e-01, -1.2825260e+00, -6.1470848e-01, -5.0824857e-01,\n",
    "        4.5474276e-01,  2.9351535e-01, -1.6820558e+00,  2.8028536e-01,\n",
    "        7.1510404e-02, -1.1397541e-01,  1.6877573e-03, -1.3896689e+00,\n",
    "       -7.1299994e-01, -5.5192190e-01,  1.3338147e+00,  9.0670723e-01,\n",
    "        2.6833752e-02, -1.1447647e+00, -1.4083545e+00, -4.1518590e-01,\n",
    "        1.0165511e+00,  2.6113531e-01,  6.4942271e-01, -1.2051920e+00,\n",
    "       -8.8982397e-01, -2.7181625e-01]]\n",
    "nparray(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array((300,300,3))\n",
    "m = K.expand_dims(r, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.shape)\n",
    "print(m.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = preprocessor.generator(\"train\", 8, start_index=0)\n",
    "for i in gen:\n",
    "    print(\"-----------------------\")\n",
    "    print((i[0][1]).shape)\n",
    "    print((i[0][1][6][5]))\n",
    "    print((i[0][1][6][13]))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in out_captions_idx[0]:\n",
    "    print(processor.idx2word[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
